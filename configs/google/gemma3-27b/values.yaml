single:
  enabled: true

resources:
  # Model is 27b and bf16
  nvidia.com/gpu: "1"

# Source: https://huggingface.co/google/gemma-3-27b-it
cli: "vllm serve google/gemma-3-27b-it
      --tensor-parallel-size 1
      --max-model-len 25000"

huggingFaceToken: true

storage:
  ephemeral:
    enabled: true
    storage: 214748364800 # 200GB
