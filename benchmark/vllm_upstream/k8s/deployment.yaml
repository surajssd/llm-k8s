apiVersion: apps/v1
kind: Deployment
metadata:
  name: benchmark-runner
  namespace: vllm-benchmark
  labels:
    app: benchmark-runner
spec:
  replicas: 1
  selector:
    matchLabels:
      app: benchmark-runner
  template:
    metadata:
      labels:
        app: benchmark-runner
    spec:
      containers:
      - name: benchmark
        image: ghcr.io/surajssd/llm-k8s/vllm-benchmark:0.7.3
        imagePullPolicy: Always
        command: ["/bin/bash"]
        args:
        - -c
        - echo -n "Run the following command:\nbash /root/benchmark/run_vllm_upstream_benchmark.sh\nSleeping now..." && sleep infinity
        env:
        - name: HF_TOKEN
          valueFrom:
            secretKeyRef:
              name: hf-token-secret
              key: token
        - name: TEST_SERVER_URL
          valueFrom:
            configMapKeyRef:
              name: benchmark-runner
              key: TEST_SERVER_URL
        - name: MODEL_NAME
          valueFrom:
            configMapKeyRef:
              name: benchmark-runner
              key: MODEL_NAME
        - name: TENSOR_PARALLEL_SIZE
          valueFrom:
            configMapKeyRef:
              name: benchmark-runner
              key: TENSOR_PARALLEL_SIZE
        - name: PIPELINE_PARALLEL_SIZE
          valueFrom:
            configMapKeyRef:
              name: benchmark-runner
              key: PIPELINE_PARALLEL_SIZE
        - name: GPU_VM_SKU
          valueFrom:
            configMapKeyRef:
              name: benchmark-runner
              key: GPU_VM_SKU
